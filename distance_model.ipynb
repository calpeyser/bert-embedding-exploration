{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "2.7.16-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597320686230",
   "display_name": "Python 2.7.16 64-bit ('venv': virtualenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:From /Users/cpeyser/Desktop/bert/venv/lib/python2.7/site-packages/bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n\n"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow.compat.v1 import keras\n",
    "import tensorflow_hub as hub\n",
    "from datetime import datetime\n",
    "import bert\n",
    "from bert import run_classifier\n",
    "from bert import optimization\n",
    "from bert import tokenization\n",
    "import numpy as np\n",
    "\n",
    "import os, re\n",
    "\n",
    "# Load all files from a directory in a DataFrame.\n",
    "def load_directory_data(directory):\n",
    "  data = {}\n",
    "  data[\"sentence\"] = []\n",
    "  data[\"sentiment\"] = []\n",
    "  for file_path in os.listdir(directory):\n",
    "    with tf.gfile.GFile(os.path.join(directory, file_path), \"r\") as f:\n",
    "      data[\"sentence\"].append(f.read())\n",
    "      data[\"sentiment\"].append(re.match(\"\\d+_(\\d+)\\.txt\", file_path).group(1))\n",
    "  return pd.DataFrame.from_dict(data)\n",
    "\n",
    "# Merge positive and negative examples, add a polarity column and shuffle.\n",
    "def load_dataset(directory):\n",
    "  pos_df = load_directory_data(os.path.join(directory, \"pos\"))\n",
    "  neg_df = load_directory_data(os.path.join(directory, \"neg\"))\n",
    "  pos_df[\"polarity\"] = 1\n",
    "  neg_df[\"polarity\"] = 0\n",
    "  return pd.concat([pos_df, neg_df]).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Download and process the dataset files.\n",
    "def download_and_load_datasets(force_download=False):\n",
    "  dataset = tf.keras.utils.get_file(\n",
    "      fname=\"aclImdb.tar.gz\", \n",
    "      origin=\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\", \n",
    "      extract=True)\n",
    "  \n",
    "  train_df = load_dataset(os.path.join(os.path.dirname(dataset), \n",
    "                                       \"aclImdb\", \"train\"))\n",
    "  test_df = load_dataset(os.path.join(os.path.dirname(dataset), \n",
    "                                      \"aclImdb\", \"test\"))\n",
    "  \n",
    "  return train_df, test_df\n",
    "\n",
    "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "def create_tokenizer_from_hub_module():\n",
    "  \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
    "  with tf.Graph().as_default():\n",
    "    bert_module = hub.Module(BERT_MODEL_HUB)\n",
    "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "    with tf.Session() as sess:\n",
    "      vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
    "                                            tokenization_info[\"do_lower_case\"]])\n",
    "      \n",
    "  return bert.tokenization.FullTokenizer(\n",
    "      vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
    "\n",
    "def debug(pass_through, tensor):\n",
    "    print_op = tf.print(tensor, output_stream=sys.stdout)\n",
    "    with tf.control_dependencies([print_op]):\n",
    "        pass_through = tf.identity(pass_through)\n",
    "    return pass_through\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "BERT_EMBEDDING_DIM = 128\n",
    "MAX_SEQ_LENGTH = 128\n",
    "BATCH_SIZE = 5\n",
    "NUM_PAIRS_PER_FPROP = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Data\n",
    "\n",
    "train, test = download_and_load_datasets()\n",
    "train = train.sample(10000)\n",
    "test = test.sample(5000)\n",
    "validation = test.sample(50)\n",
    "DATA_COLUMN = 'sentence'\n",
    "LABEL_COLUMN = 'polarity'\n",
    "# label_list is the list of labels, i.e. True, False or 0, 1 or 'dog', 'cat'\n",
    "label_list = [0, 1]\n",
    "# Use the InputExample class from BERT's run_classifier code to create examples from the data\n",
    "train_InputExamples = train.apply(lambda x: bert.run_classifier.InputExample(guid=None, text_a = x[DATA_COLUMN], text_b = None, label = x[LABEL_COLUMN]), axis = 1)\n",
    "test_InputExamples = test.apply(lambda x: bert.run_classifier.InputExample(guid=None,text_a = x[DATA_COLUMN], text_b = None, label = x[LABEL_COLUMN]), axis = 1)\n",
    "validation_InputExamples = validation.apply(lambda x: bert.run_classifier.InputExample(guid=None,text_a = x[DATA_COLUMN], text_b = None, label = x[LABEL_COLUMN]), axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "\n",
    "import os\n",
    "\n",
    "def vocab_file():\n",
    "    vocab_file = os.path.join(os.path.abspath(''), 'small_bert_bert_uncased_L-2_H-128_A-2_1/assets/vocab.txt')\n",
    "    return vocab_file\n",
    "\n",
    "def read_vocab():\n",
    "    f = open(vocab_file(), 'rb')\n",
    "    words = f.readlines()\n",
    "    words = [word.rstrip() for word in words]\n",
    "    return words\n",
    "\n",
    "def has_ing():\n",
    "    vocab = read_vocab()\n",
    "    return [s.endswith('ing') for s in vocab]\n",
    "\n",
    "def word_length():\n",
    "    vocab = read_vocab()\n",
    "    return [len(s) for s in vocab]\n",
    "\n",
    "class WordLengthDistanceFunction(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(WordLengthDistanceFunction, self).__init__()\n",
    "        self.lookup = tf.constant(word_length())\n",
    "\n",
    "    def distance(self, ids_1, ids_2):\n",
    "        lengths_1 = tf.gather(self.lookup, ids_1)\n",
    "        lengths_2 = tf.gather(self.lookup, ids_2)\n",
    "        distance = tf.math.abs(lengths_2 - lengths_1)\n",
    "        distance = tf.cast(distance, dtype=tf.float32)\n",
    "        return distance\n",
    "\n",
    "class IngDistanceFunction(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(IngDistanceFunction, self).__init__()\n",
    "        self.lookup = tf.constant(has_ing())\n",
    "\n",
    "    def is_ing(self, ids):\n",
    "        ings = tf.gather(self.lookup, ids)\n",
    "        return ings\n",
    "\n",
    "    def distance(self, ids_1, ids_2):\n",
    "        ings_1 = tf.gather(self.lookup, ids_1)\n",
    "        ings_2 = tf.gather(self.lookup, ids_2)\n",
    "        are_different = tf.logical_xor(ings_1, ings_2)\n",
    "        distance = tf.cast(are_different, dtype=tf.float32)\n",
    "        return distance\n",
    "\n",
    "def bert_model(features, labels, mode, params):\n",
    "    batch_size = params['batch_size']\n",
    "\n",
    "    def _run_bert(input_ids, input_mask, segment_ids):\n",
    "        bert_module = hub.Module(\n",
    "            \"https://tfhub.dev/google/small_bert/bert_uncased_L-2_H-128_A-2/1\",\n",
    "            trainable=True, tags={\"train\"})\n",
    "        bert_inputs = dict(\n",
    "            input_ids=input_ids,\n",
    "            input_mask=input_mask,\n",
    "            segment_ids=segment_ids)\n",
    "        bert_outputs = bert_module(bert_inputs, signature=\"tokens\", as_dict=True)\n",
    "        #pooled_output = bert_outputs[\"pooled_output\"]\n",
    "        sequence_output = tf.stop_gradient(bert_outputs[\"sequence_output\"])\n",
    "        return sequence_output\n",
    "\n",
    "    with tf.variable_scope('bert_1'):\n",
    "        bert_embs_1 = _run_bert(features['input_ids_1'], features['input_mask_1'], features['segment_ids_1'])\n",
    "    with tf.variable_scope('bert_2'):\n",
    "        bert_embs_2 = _run_bert(features['input_ids_2'], features['input_mask_2'], features['segment_ids_2'])\n",
    "\n",
    "    feature_extracting_projection = tf.get_variable(\n",
    "        \"feature_extracting_projection\",\n",
    "        [BERT_EMBEDDING_DIM, BERT_EMBEDDING_DIM],\n",
    "        initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "\n",
    "    def _apply_extractor(bert_embs):\n",
    "        def _extract_single_embedding_vector(embedding_vector):\n",
    "            embedding_vector = tf.expand_dims(embedding_vector, axis=0)\n",
    "            res = tf.matmul(embedding_vector, feature_extracting_projection)\n",
    "            return tf.squeeze(res)\n",
    "\n",
    "        def _extract_sequence_of_embeddings(embedding_seq):\n",
    "            return tf.map_fn(_extract_single_embedding_vector, embedding_seq, infer_shape=False)\n",
    "\n",
    "        logits = tf.map_fn(_extract_sequence_of_embeddings, bert_embs, infer_shape=False)\n",
    "        logits = tf.ensure_shape(logits, [batch_size, MAX_SEQ_LENGTH, BERT_EMBEDDING_DIM])\n",
    "        return logits\n",
    "        \n",
    "    with tf.variable_scope('extract_1'):\n",
    "        extracted_features_1 = _apply_extractor(bert_embs_1)\n",
    "    with tf.variable_scope('extract_2'):\n",
    "        extracted_features_2 = _apply_extractor(bert_embs_2)\n",
    "\n",
    "    def _sample(ids, mask, feats):\n",
    "        def _get_lowest_index_with_zero(x):\n",
    "            is_zero = tf.where(tf.equal(x, 0))\n",
    "            is_zero = tf.squeeze(is_zero)\n",
    "            is_zero = tf.cast(is_zero, dtype=tf.int32)\n",
    "            earliest_zero = tf.cond(\n",
    "                tf.equal(tf.size(is_zero), 0),\n",
    "                lambda: tf.squeeze(tf.shape(x)),\n",
    "                lambda: tf.reduce_min(is_zero))\n",
    "            return earliest_zero\n",
    "        # [batch_size], where each element is the last index that is not masked\n",
    "        example_is_ended = tf.map_fn(_get_lowest_index_with_zero, mask, infer_shape=False)\n",
    "\n",
    "        def _sample_indexes_for_example(is_ended):\n",
    "            inx = tf.random.uniform([NUM_PAIRS_PER_FPROP], minval=0, maxval=is_ended, dtype=tf.int32)\n",
    "            return inx\n",
    "\n",
    "        # [batch_size, NUM_PAIRS_PER_FPROP], sampled indexes\n",
    "        indexes = tf.map_fn(_sample_indexes_for_example, example_is_ended, infer_shape=False)\n",
    "\n",
    "        def _take(inputs):\n",
    "            p, ind = inputs\n",
    "            return tf.gather(p, ind), ind\n",
    "\n",
    "        # [batch_size, NUM_PAIRS_PER_FPROP], sampled ids and extracted features\n",
    "        sampled_ids, _ = tf.map_fn(_take, (ids, indexes), infer_shape=False)\n",
    "        sampled_ids = tf.ensure_shape(sampled_ids, [batch_size, NUM_PAIRS_PER_FPROP])\n",
    "        sampled_feats, _ = tf.map_fn(_take, (feats, indexes), infer_shape=False)\n",
    "        sampled_feats = tf.ensure_shape(sampled_feats, [batch_size, NUM_PAIRS_PER_FPROP, BERT_EMBEDDING_DIM])\n",
    "\n",
    "        return sampled_ids, sampled_feats\n",
    "\n",
    "    with tf.variable_scope('sample_ids_and_feats_1'):\n",
    "        sampled_ids_1, sampled_feats_1 = _sample(features['input_ids_1'], features['input_mask_1'], extracted_features_1)     \n",
    "    with tf.variable_scope('sample_ids_and_feats_2'):\n",
    "        sampled_ids_2, sampled_feats_2 = _sample(features['input_ids_2'], features['input_mask_2'], extracted_features_2)\n",
    "\n",
    "    with tf.variable_scope('loss'):\n",
    "        def _pointwise_euclidean_distance(a, b):\n",
    "            difference = tf.math.abs(a - b)\n",
    "            squared_difference = tf.math.square(difference)\n",
    "            sum_of_squared_difference = tf.reduce_sum(squared_difference, axis=-1)\n",
    "            euclidean_distance = tf.math.sqrt(sum_of_squared_difference)\n",
    "            return euclidean_distance\n",
    "\n",
    "        distance_function = WordLengthDistanceFunction()\n",
    "        true_distance = distance_function.distance(sampled_ids_1, sampled_ids_2)\n",
    "        feats_distance = _pointwise_euclidean_distance(sampled_feats_1, sampled_feats_2)\n",
    "        \n",
    "        loss_matrix = tf.math.abs(true_distance - feats_distance)\n",
    "        loss = tf.reduce_mean(loss_matrix)\n",
    "\n",
    "    with tf.variable_scope('metrics'):\n",
    "        pass\n",
    "        ings_1 = distance_function.is_ing(sampled_ids_1)\n",
    "        ings_2 = distance_function.is_ing(sampled_ids_2)\n",
    "\n",
    "        both_ing = tf.logical_and(ings_1, ings_2)\n",
    "        either_ing = tf.logical_xor(ings_1, ings_2)\n",
    "        neither_ing = tf.logical_not(tf.logical_or(ings_1, ings_2))\n",
    "\n",
    "        def _avg_feats_distance(feats_distance_matrix, indexes):\n",
    "            indexes_as_float = tf.cast(indexes, dtype=tf.float32)\n",
    "            num_matches = tf.reduce_sum(indexes_as_float)\n",
    "            matching_distances = tf.math.multiply(feats_distance_matrix, indexes_as_float)\n",
    "            sum_distances = tf.reduce_sum(matching_distances)\n",
    "            return tf.cond(\n",
    "                tf.equal(num_matches, 0),\n",
    "                lambda: 0.0,\n",
    "                lambda: (sum_distances / num_matches)\n",
    "            )\n",
    "\n",
    "        both_dists = _avg_feats_distance(feats_distance, both_ing)\n",
    "        either_dists = _avg_feats_distance(feats_distance, either_ing)\n",
    "        neither_dists = _avg_feats_distance(feats_distance, neither_ing)\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        opt = tf.train.AdamOptimizer(learning_rate=0.00001, beta1=0.9, beta2=0.999, epsilon=1e-08)\n",
    "        train_op = opt.minimize(loss, global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\n",
    "    elif mode == tf.estimator.ModeKeys.EVAL:\n",
    "        pass\n",
    "        # def _metric_fn(both_dists, either_dists, neither_dists):\n",
    "        #     return {\n",
    "        #         'both_dists': tf.metrics.mean(both_dists),\n",
    "        #         'either_dists': tf.metrics.mean(either_dists),\n",
    "        #         'neither_dists': tf.metrics.mean(neither_dists),\n",
    "        #     }\n",
    "        # return tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops=_metric_fn(both_dists, either_dists, neither_dists))\n",
    "    elif mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        # In prediction mode, we emit sampled features for the entirety of the first input sequence\n",
    "        res = {\n",
    "            'ids': features['input_ids_1'],\n",
    "            'masks': features['input_mask_1'],\n",
    "            'extracted_features': extracted_features_1,\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Input\n",
    "def make_input_fn(examples):\n",
    "\n",
    "    def input_fn():\n",
    "        tokenizer = create_tokenizer_from_hub_module()\n",
    "        feats = bert.run_classifier.convert_examples_to_features(examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "        vanilla_fn = bert.run_classifier.input_fn_builder(\n",
    "            features=feats,\n",
    "            seq_length=MAX_SEQ_LENGTH,\n",
    "            is_training=True,\n",
    "            drop_remainder=False\n",
    "        )\n",
    "        params = {\n",
    "            \"batch_size\": BATCH_SIZE\n",
    "        }        \n",
    "        ds = vanilla_fn(params)\n",
    "        #ds = ds.shuffle(buffer_size=1000)\n",
    "        ds = ds.batch(2)\n",
    "    \n",
    "        def _unstack(record):\n",
    "            stacked_input_ids = tf.ensure_shape(record['input_ids'], [2, BATCH_SIZE, MAX_SEQ_LENGTH])\n",
    "            input_ids_1, input_ids_2 = tf.unstack(stacked_input_ids, axis=0)\n",
    "\n",
    "            stacked_input_mask = tf.ensure_shape(record['input_mask'], [2, BATCH_SIZE, MAX_SEQ_LENGTH])\n",
    "            input_mask_1, input_mask_2 = tf.unstack(stacked_input_mask, axis=0)\n",
    "\n",
    "            stacked_segment_ids = tf.ensure_shape(record['segment_ids'], [2, BATCH_SIZE, MAX_SEQ_LENGTH])\n",
    "            segment_ids_1, segment_ids_2 = tf.unstack(stacked_segment_ids, axis=0)\n",
    "\n",
    "            return {\n",
    "                'input_ids_1': input_ids_1,\n",
    "                'input_ids_2': input_ids_2,\n",
    "                'input_mask_1': input_mask_1,\n",
    "                'input_mask_2': input_mask_2,\n",
    "                'segment_ids_1': segment_ids_1,\n",
    "                'segment_ids_2': segment_ids_2\n",
    "            }\n",
    "        ds = ds.map(_unstack)\n",
    "\n",
    "        return ds\n",
    "    return input_fn\n",
    "\n",
    "# tf.reset_default_graph()\n",
    "# tf.disable_v2_behavior()\n",
    "\n",
    "# features = train_InputExamples[:(BATCH_SIZE * 5)]\n",
    "# ds = make_input_fn(features)()._dataset\n",
    "# it = tf.data.make_one_shot_iterator(ds)\n",
    "# with tf.Session() as sess:\n",
    "#     feats = it.get_next()\n",
    "#     model_output = bert_model(feats, None, tf.estimator.ModeKeys.TRAIN, {'batch_size': BATCH_SIZE})\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "#     print(model_output)\n",
    "#     n, s = sess.run([model_output, tf.shape(model_output)])\n",
    "#     print(n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "INFO:tensorflow:Using config: {'_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\ngraph_options {\n  rewrite_options {\n    meta_optimizer_iterations: ONE\n  }\n}\n, '_keep_checkpoint_max': 100, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x141bcda50>, '_model_dir': '/Users/cpeyser/Desktop/bert/ckpts/6/', '_protocol': None, '_save_checkpoints_steps': 500, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_session_creation_timeout_secs': 7200, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_experimental_max_worker_delay_secs': None, '_evaluation_master': '', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': ''}\nINFO:tensorflow:Using config: {'_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\ngraph_options {\n  rewrite_options {\n    meta_optimizer_iterations: ONE\n  }\n}\n, '_keep_checkpoint_max': 100, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x141bcda50>, '_model_dir': '/Users/cpeyser/Desktop/bert/ckpts/6/', '_protocol': None, '_save_checkpoints_steps': 500, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_session_creation_timeout_secs': 7200, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_experimental_max_worker_delay_secs': None, '_evaluation_master': '', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': ''}\n"
    }
   ],
   "source": [
    "run_config = tf.estimator.RunConfig(\n",
    "    model_dir=os.path.join(os.path.abspath(''), 'ckpts/6/'),\n",
    "    keep_checkpoint_max=100,\n",
    "    save_checkpoints_steps=500\n",
    ")\n",
    "\n",
    "estimator = tf.estimator.Estimator(\n",
    "    model_fn=bert_model,\n",
    "    config=run_config,\n",
    "    params= {\n",
    "        'batch_size': BATCH_SIZE\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\nINFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\nINFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\nINFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\nINFO:tensorflow:label: 1 (id = 1)\nINFO:tensorflow:label: 1 (id = 1)\nINFO:tensorflow:*** Example ***\nINFO:tensorflow:*** Example ***\nINFO:tensorflow:guid: None\nINFO:tensorflow:guid: None\nINFO:tensorflow:tokens: [CLS] we usually think of the british as the experts at rendering great adventure from the imperial age , with the likes of the four feathers ( 1939 ) and zulu , simply because the imperial age was , for the most part , british . here , in the wind and the lion , we see a wonderful rendering of america ' s own imperial age . < br / > < br / > america ' s projection of power under teddy roosevelt is the backdrop for this conventional tale of the kidnapped dams ##el who , despite her gen ##tility , is sm ##itte ##n by the rough , manly nobility of her capt ##or , who in turn is di ##sar ##med by [SEP]\nINFO:tensorflow:tokens: [CLS] we usually think of the british as the experts at rendering great adventure from the imperial age , with the likes of the four feathers ( 1939 ) and zulu , simply because the imperial age was , for the most part , british . here , in the wind and the lion , we see a wonderful rendering of america ' s own imperial age . < br / > < br / > america ' s projection of power under teddy roosevelt is the backdrop for this conventional tale of the kidnapped dams ##el who , despite her gen ##tility , is sm ##itte ##n by the rough , manly nobility of her capt ##or , who in turn is di ##sar ##med by [SEP]\nINFO:tensorflow:input_ids: 101 2057 2788 2228 1997 1996 2329 2004 1996 8519 2012 14259 2307 6172 2013 1996 4461 2287 1010 2007 1996 7777 1997 1996 2176 12261 1006 3912 1007 1998 27359 1010 3432 2138 1996 4461 2287 2001 1010 2005 1996 2087 2112 1010 2329 1012 2182 1010 1999 1996 3612 1998 1996 7006 1010 2057 2156 1037 6919 14259 1997 2637 1005 1055 2219 4461 2287 1012 1026 7987 1013 1028 1026 7987 1013 1028 2637 1005 1055 13996 1997 2373 2104 11389 8573 2003 1996 18876 2005 2023 7511 6925 1997 1996 11364 17278 2884 2040 1010 2750 2014 8991 18724 1010 2003 15488 27100 2078 2011 1996 5931 1010 19385 11760 1997 2014 14408 2953 1010 2040 1999 2735 2003 4487 10286 7583 2011 102\nINFO:tensorflow:input_ids: 101 2057 2788 2228 1997 1996 2329 2004 1996 8519 2012 14259 2307 6172 2013 1996 4461 2287 1010 2007 1996 7777 1997 1996 2176 12261 1006 3912 1007 1998 27359 1010 3432 2138 1996 4461 2287 2001 1010 2005 1996 2087 2112 1010 2329 1012 2182 1010 1999 1996 3612 1998 1996 7006 1010 2057 2156 1037 6919 14259 1997 2637 1005 1055 2219 4461 2287 1012 1026 7987 1013 1028 1026 7987 1013 1028 2637 1005 1055 13996 1997 2373 2104 11389 8573 2003 1996 18876 2005 2023 7511 6925 1997 1996 11364 17278 2884 2040 1010 2750 2014 8991 18724 1010 2003 15488 27100 2078 2011 1996 5931 1010 19385 11760 1997 2014 14408 2953 1010 2040 1999 2735 2003 4487 10286 7583 2011 102\nINFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\nINFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\nINFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\nINFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\nINFO:tensorflow:label: 1 (id = 1)\nINFO:tensorflow:label: 1 (id = 1)\nINFO:tensorflow:*** Example ***\nINFO:tensorflow:*** Example ***\nINFO:tensorflow:guid: None\nINFO:tensorflow:guid: None\nINFO:tensorflow:tokens: [CLS] as if the world needed another sea ##gal movie . add a bunch of actors who , well . . . are not really actors , a bunch of heavy metal music to compliment the rap and of course , a hot looking crazy chick in leather with no hips , and we prevent ourselves from being half past budget . why , oh why do people sabotage themselves by participating in such films ? < br / > < br / > fbi capture two buddies and send them to \" new al ##cat ##raz , \" where the prison ' s first inmate to be executed has unexpected guests . < br / > < br / > first rate acting all around , [SEP]\nINFO:tensorflow:tokens: [CLS] as if the world needed another sea ##gal movie . add a bunch of actors who , well . . . are not really actors , a bunch of heavy metal music to compliment the rap and of course , a hot looking crazy chick in leather with no hips , and we prevent ourselves from being half past budget . why , oh why do people sabotage themselves by participating in such films ? < br / > < br / > fbi capture two buddies and send them to \" new al ##cat ##raz , \" where the prison ' s first inmate to be executed has unexpected guests . < br / > < br / > first rate acting all around , [SEP]\nINFO:tensorflow:input_ids: 101 2004 2065 1996 2088 2734 2178 2712 9692 3185 1012 5587 1037 9129 1997 5889 2040 1010 2092 1012 1012 1012 2024 2025 2428 5889 1010 1037 9129 1997 3082 3384 2189 2000 19394 1996 9680 1998 1997 2607 1010 1037 2980 2559 4689 14556 1999 5898 2007 2053 6700 1010 1998 2057 4652 9731 2013 2108 2431 2627 5166 1012 2339 1010 2821 2339 2079 2111 20223 3209 2011 8019 1999 2107 3152 1029 1026 7987 1013 1028 1026 7987 1013 1028 8495 5425 2048 24115 1998 4604 2068 2000 1000 2047 2632 11266 20409 1010 1000 2073 1996 3827 1005 1055 2034 24467 2000 2022 6472 2038 9223 6368 1012 1026 7987 1013 1028 1026 7987 1013 1028 2034 3446 3772 2035 2105 1010 102\nINFO:tensorflow:input_ids: 101 2004 2065 1996 2088 2734 2178 2712 9692 3185 1012 5587 1037 9129 1997 5889 2040 1010 2092 1012 1012 1012 2024 2025 2428 5889 1010 1037 9129 1997 3082 3384 2189 2000 19394 1996 9680 1998 1997 2607 1010 1037 2980 2559 4689 14556 1999 5898 2007 2053 6700 1010 1998 2057 4652 9731 2013 2108 2431 2627 5166 1012 2339 1010 2821 2339 2079 2111 20223 3209 2011 8019 1999 2107 3152 1029 1026 7987 1013 1028 1026 7987 1013 1028 8495 5425 2048 24115 1998 4604 2068 2000 1000 2047 2632 11266 20409 1010 1000 2073 1996 3827 1005 1055 2034 24467 2000 2022 6472 2038 9223 6368 1012 1026 7987 1013 1028 1026 7987 1013 1028 2034 3446 3772 2035 2105 1010 102\nINFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\nINFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\nINFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\nINFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\nINFO:tensorflow:label: 0 (id = 0)\nINFO:tensorflow:label: 0 (id = 0)\nINFO:tensorflow:*** Example ***\nINFO:tensorflow:*** Example ***\nINFO:tensorflow:guid: None\nINFO:tensorflow:guid: None\nINFO:tensorflow:tokens: [CLS] i can remember seeing this movie when i was very young and several times on tv since then . i have always liked it . i have noticed on the print shown on local tv that one scene has reversed film . it is the one where they are hiding behind the rock out ##cr ##op ( it looks like va ##sque ##z rocks near los angeles ) watching the indians ride by . if you look carefully , you will notice that suddenly all the soldiers are left - handed ! it is only a short segment and i have to admit that it took me years to notice it . < br / > < br / > as far as history goes , [SEP]\nINFO:tensorflow:tokens: [CLS] i can remember seeing this movie when i was very young and several times on tv since then . i have always liked it . i have noticed on the print shown on local tv that one scene has reversed film . it is the one where they are hiding behind the rock out ##cr ##op ( it looks like va ##sque ##z rocks near los angeles ) watching the indians ride by . if you look carefully , you will notice that suddenly all the soldiers are left - handed ! it is only a short segment and i have to admit that it took me years to notice it . < br / > < br / > as far as history goes , [SEP]\nINFO:tensorflow:input_ids: 101 1045 2064 3342 3773 2023 3185 2043 1045 2001 2200 2402 1998 2195 2335 2006 2694 2144 2059 1012 1045 2031 2467 4669 2009 1012 1045 2031 4384 2006 1996 6140 3491 2006 2334 2694 2008 2028 3496 2038 11674 2143 1012 2009 2003 1996 2028 2073 2027 2024 6318 2369 1996 2600 2041 26775 7361 1006 2009 3504 2066 12436 17729 2480 5749 2379 3050 3349 1007 3666 1996 6505 4536 2011 1012 2065 2017 2298 5362 1010 2017 2097 5060 2008 3402 2035 1996 3548 2024 2187 1011 4375 999 2009 2003 2069 1037 2460 6903 1998 1045 2031 2000 6449 2008 2009 2165 2033 2086 2000 5060 2009 1012 1026 7987 1013 1028 1026 7987 1013 1028 2004 2521 2004 2381 3632 1010 102\nINFO:tensorflow:input_ids: 101 1045 2064 3342 3773 2023 3185 2043 1045 2001 2200 2402 1998 2195 2335 2006 2694 2144 2059 1012 1045 2031 2467 4669 2009 1012 1045 2031 4384 2006 1996 6140 3491 2006 2334 2694 2008 2028 3496 2038 11674 2143 1012 2009 2003 1996 2028 2073 2027 2024 6318 2369 1996 2600 2041 26775 7361 1006 2009 3504 2066 12436 17729 2480 5749 2379 3050 3349 1007 3666 1996 6505 4536 2011 1012 2065 2017 2298 5362 1010 2017 2097 5060 2008 3402 2035 1996 3548 2024 2187 1011 4375 999 2009 2003 2069 1037 2460 6903 1998 1045 2031 2000 6449 2008 2009 2165 2033 2086 2000 5060 2009 1012 1026 7987 1013 1028 1026 7987 1013 1028 2004 2521 2004 2381 3632 1010 102\nINFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\nINFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\nINFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\nINFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\nINFO:tensorflow:label: 1 (id = 1)\nINFO:tensorflow:label: 1 (id = 1)\nINFO:tensorflow:*** Example ***\nINFO:tensorflow:*** Example ***\nINFO:tensorflow:guid: None\nINFO:tensorflow:guid: None\nINFO:tensorflow:tokens: [CLS] a somewhat typical bit of filmmaking from this era . obviously , it was first conceived into this world for the stage , but nonetheless a very good film from beginning to end . peter o ' tool ##e and susannah york get to do their stage performance act for the silver screen and both do it effectively . there is very little in the way of story and anyone not familiar with this type of off beat character study may be a little put off by it . all in all , though , a good film in which peter o ' tool ##e and susannah york get to over ##act . [SEP]\nINFO:tensorflow:tokens: [CLS] a somewhat typical bit of filmmaking from this era . obviously , it was first conceived into this world for the stage , but nonetheless a very good film from beginning to end . peter o ' tool ##e and susannah york get to do their stage performance act for the silver screen and both do it effectively . there is very little in the way of story and anyone not familiar with this type of off beat character study may be a little put off by it . all in all , though , a good film in which peter o ' tool ##e and susannah york get to over ##act . [SEP]\nINFO:tensorflow:input_ids: 101 1037 5399 5171 2978 1997 24466 2013 2023 3690 1012 5525 1010 2009 2001 2034 10141 2046 2023 2088 2005 1996 2754 1010 2021 9690 1037 2200 2204 2143 2013 2927 2000 2203 1012 2848 1051 1005 6994 2063 1998 20471 2259 2131 2000 2079 2037 2754 2836 2552 2005 1996 3165 3898 1998 2119 2079 2009 6464 1012 2045 2003 2200 2210 1999 1996 2126 1997 2466 1998 3087 2025 5220 2007 2023 2828 1997 2125 3786 2839 2817 2089 2022 1037 2210 2404 2125 2011 2009 1012 2035 1999 2035 1010 2295 1010 1037 2204 2143 1999 2029 2848 1051 1005 6994 2063 1998 20471 2259 2131 2000 2058 18908 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0\nINFO:tensorflow:input_ids: 101 1037 5399 5171 2978 1997 24466 2013 2023 3690 1012 5525 1010 2009 2001 2034 10141 2046 2023 2088 2005 1996 2754 1010 2021 9690 1037 2200 2204 2143 2013 2927 2000 2203 1012 2848 1051 1005 6994 2063 1998 20471 2259 2131 2000 2079 2037 2754 2836 2552 2005 1996 3165 3898 1998 2119 2079 2009 6464 1012 2045 2003 2200 2210 1999 1996 2126 1997 2466 1998 3087 2025 5220 2007 2023 2828 1997 2125 3786 2839 2817 2089 2022 1037 2210 2404 2125 2011 2009 1012 2035 1999 2035 1010 2295 1010 1037 2204 2143 1999 2029 2848 1051 1005 6994 2063 1998 20471 2259 2131 2000 2058 18908 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0\nINFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\nINFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\nINFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\nINFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\nINFO:tensorflow:label: 1 (id = 1)\nINFO:tensorflow:label: 1 (id = 1)\nINFO:tensorflow:Calling model_fn.\nINFO:tensorflow:Calling model_fn.\nINFO:tensorflow:Saver not created because there are no variables in the graph to restore\nINFO:tensorflow:Saver not created because there are no variables in the graph to restore\nINFO:tensorflow:Saver not created because there are no variables in the graph to restore\nINFO:tensorflow:Saver not created because there are no variables in the graph to restore\nINFO:tensorflow:Saver not created because there are no variables in the graph to restore\nINFO:tensorflow:Saver not created because there are no variables in the graph to restore\nINFO:tensorflow:Saver not created because there are no variables in the graph to restore\nINFO:tensorflow:Saver not created because there are no variables in the graph to restore\nINFO:tensorflow:Done calling model_fn.\nINFO:tensorflow:Done calling model_fn.\nINFO:tensorflow:Create CheckpointSaverHook.\nINFO:tensorflow:Create CheckpointSaverHook.\nINFO:tensorflow:Graph was finalized.\nINFO:tensorflow:Graph was finalized.\nINFO:tensorflow:Restoring parameters from /Users/cpeyser/Desktop/bert/ckpts/6/model.ckpt-0\nINFO:tensorflow:Restoring parameters from /Users/cpeyser/Desktop/bert/ckpts/6/model.ckpt-0\nWARNING:tensorflow:From /Users/cpeyser/Desktop/bert/venv/lib/python2.7/site-packages/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse standard file utilities to get mtimes.\nWARNING:tensorflow:From /Users/cpeyser/Desktop/bert/venv/lib/python2.7/site-packages/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse standard file utilities to get mtimes.\nINFO:tensorflow:Running local_init_op.\nINFO:tensorflow:Running local_init_op.\nINFO:tensorflow:Done running local_init_op.\nINFO:tensorflow:Done running local_init_op.\nINFO:tensorflow:Saving checkpoints for 0 into /Users/cpeyser/Desktop/bert/ckpts/6/model.ckpt.\nINFO:tensorflow:Saving checkpoints for 0 into /Users/cpeyser/Desktop/bert/ckpts/6/model.ckpt.\nINFO:tensorflow:loss = 1.6519864, step = 1\nINFO:tensorflow:loss = 1.6519864, step = 1\nINFO:tensorflow:global_step/sec: 0.924952\nINFO:tensorflow:global_step/sec: 0.924952\nINFO:tensorflow:loss = 1.5695161, step = 101 (108.117 sec)\nINFO:tensorflow:loss = 1.5695161, step = 101 (108.117 sec)\nINFO:tensorflow:global_step/sec: 0.988019\nINFO:tensorflow:global_step/sec: 0.988019\nINFO:tensorflow:loss = 1.6310316, step = 201 (101.216 sec)\nINFO:tensorflow:loss = 1.6310316, step = 201 (101.216 sec)\nINFO:tensorflow:global_step/sec: 0.977147\nINFO:tensorflow:global_step/sec: 0.977147\nINFO:tensorflow:loss = 1.6202726, step = 301 (102.336 sec)\nINFO:tensorflow:loss = 1.6202726, step = 301 (102.336 sec)\nINFO:tensorflow:global_step/sec: 0.986576\nINFO:tensorflow:global_step/sec: 0.986576\nINFO:tensorflow:loss = 1.5001053, step = 401 (101.359 sec)\nINFO:tensorflow:loss = 1.5001053, step = 401 (101.359 sec)\nINFO:tensorflow:Saving checkpoints for 500 into /Users/cpeyser/Desktop/bert/ckpts/6/model.ckpt.\nINFO:tensorflow:Saving checkpoints for 500 into /Users/cpeyser/Desktop/bert/ckpts/6/model.ckpt.\nINFO:tensorflow:Loss for final step: 1.556704.\nINFO:tensorflow:Loss for final step: 1.556704.\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow_estimator.python.estimator.estimator.Estimator at 0x14469eed0>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "estimator.train(input_fn=make_input_fn(validation_InputExamples), max_steps=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "CKPT=os.path.join(os.path.abspath(''), 'ckpts/3/model.ckpt-1000')\n",
    "estimator.evaluate(input_fn=make_input_fn(test_InputExamples), steps=100, checkpoint_path=CKPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CKPT=os.path.join(os.path.abspath(''), 'ckpts/3/model.ckpt-1000')\n",
    "predictions = estimator.predict(input_fn=make_input_fn(test_InputExamples), checkpoint_path=CKPT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = []\n",
    "for i in predictions:\n",
    "    preds.append(i)\n",
    "    if len(preds) >= 100:\n",
    "        break\n",
    "\n",
    "vocab = read_vocab()\n",
    "def _lookup(id):\n",
    "    return vocab[id]\n",
    "v_lookup = np.vectorize(_lookup)\n",
    "\n",
    "def _ends_ing(id):\n",
    "    return vocab[id].endswith('ing')\n",
    "v_ends_ing = np.vectorize(_ends_ing)\n",
    "\n",
    "def _add_words_to_prediction(p):\n",
    "    p['words'] = v_lookup(p['ids'])\n",
    "    p['ends_with_ing'] = v_ends_ing(p['ids'])\n",
    "    return p\n",
    "\n",
    "preds_with_words = [_add_words_to_prediction(p) for p in preds]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pred_0 = preds_with_words[13]\n",
    "feats = pred_0['extracted_features']\n",
    "ends_with_ing = pred_0['ends_with_ing']\n",
    "\n",
    "feats_no_ing = [f for (i, f) in enumerate(feats) if not ends_with_ing[i]]\n",
    "feats_ing = [f for (i, f) in enumerate(feats) if ends_with_ing[i]]\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(211)\n",
    "plt.plot(feats_no_ing, np.ones_like(feats_no_ing), 'bo')\n",
    "plt.axis([-0.05, 0.02, 0.9, 1.1])\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(feats_ing, np.ones_like(feats_ing), 'ro')\n",
    "plt.axis([-0.05, 0.02, 0.9, 1.1])\n",
    "\n",
    "plt.show()\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}