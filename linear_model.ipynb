{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1596456633884",
   "display_name": "Python 2.7.16 64-bit ('venv': virtualenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:From /Users/cpeyser/Desktop/bert/venv/lib/python2.7/site-packages/bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n\n"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow.compat.v1 import keras\n",
    "import tensorflow_hub as hub\n",
    "from datetime import datetime\n",
    "import bert\n",
    "from bert import run_classifier\n",
    "from bert import optimization\n",
    "from bert import tokenization\n",
    "\n",
    "import os, re\n",
    "\n",
    "# Load all files from a directory in a DataFrame.\n",
    "def load_directory_data(directory):\n",
    "  data = {}\n",
    "  data[\"sentence\"] = []\n",
    "  data[\"sentiment\"] = []\n",
    "  for file_path in os.listdir(directory):\n",
    "    with tf.gfile.GFile(os.path.join(directory, file_path), \"r\") as f:\n",
    "      data[\"sentence\"].append(f.read())\n",
    "      data[\"sentiment\"].append(re.match(\"\\d+_(\\d+)\\.txt\", file_path).group(1))\n",
    "  return pd.DataFrame.from_dict(data)\n",
    "\n",
    "# Merge positive and negative examples, add a polarity column and shuffle.\n",
    "def load_dataset(directory):\n",
    "  pos_df = load_directory_data(os.path.join(directory, \"pos\"))\n",
    "  neg_df = load_directory_data(os.path.join(directory, \"neg\"))\n",
    "  pos_df[\"polarity\"] = 1\n",
    "  neg_df[\"polarity\"] = 0\n",
    "  return pd.concat([pos_df, neg_df]).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Download and process the dataset files.\n",
    "def download_and_load_datasets(force_download=False):\n",
    "  dataset = tf.keras.utils.get_file(\n",
    "      fname=\"aclImdb.tar.gz\", \n",
    "      origin=\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\", \n",
    "      extract=True)\n",
    "  \n",
    "  train_df = load_dataset(os.path.join(os.path.dirname(dataset), \n",
    "                                       \"aclImdb\", \"train\"))\n",
    "  test_df = load_dataset(os.path.join(os.path.dirname(dataset), \n",
    "                                      \"aclImdb\", \"test\"))\n",
    "  \n",
    "  return train_df, test_df\n",
    "\n",
    "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "def create_tokenizer_from_hub_module():\n",
    "  \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
    "  with tf.Graph().as_default():\n",
    "    bert_module = hub.Module(BERT_MODEL_HUB)\n",
    "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "    with tf.Session() as sess:\n",
    "      vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
    "                                            tokenization_info[\"do_lower_case\"]])\n",
    "      \n",
    "  return bert.tokenization.FullTokenizer(\n",
    "      vocab_file=vocab_file, do_lower_case=do_lower_case)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train, test = download_and_load_datasets()\n",
    "train = train.sample(5000)\n",
    "test = test.sample(5000)\n",
    "DATA_COLUMN = 'sentence'\n",
    "LABEL_COLUMN = 'polarity'\n",
    "# label_list is the list of labels, i.e. True, False or 0, 1 or 'dog', 'cat'\n",
    "label_list = [0, 1]\n",
    "# Use the InputExample class from BERT's run_classifier code to create examples from the data\n",
    "train_InputExamples = train.apply(lambda x: bert.run_classifier.InputExample(guid=None, text_a = x[DATA_COLUMN], text_b = None, label = x[LABEL_COLUMN]), axis = 1)\n",
    "\n",
    "test_InputExamples = test.apply(lambda x: bert.run_classifier.InputExample(guid=None,text_a = x[DATA_COLUMN], text_b = None, label = x[LABEL_COLUMN]), axis = 1)\n",
    "\n",
    "MAX_SEQ_LENGTH = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "\n",
    "BERT_EMBEDDING_DIM = 128\n",
    "NUM_LABELS = 2\n",
    "\n",
    "def bert_model(features, labels, mode, params):\n",
    "    batch_size = params['batch_size']\n",
    "\n",
    "    input_ids = features['input_ids']\n",
    "    input_mask = features['input_mask']\n",
    "    segment_ids = features['segment_ids']\n",
    "    labels_one_hot = tf.one_hot(labels, depth=2, on_value=1.0, off_value=0.0, dtype=tf.float32)\n",
    "    bert_module = hub.Module(\n",
    "        \"https://tfhub.dev/google/small_bert/bert_uncased_L-2_H-128_A-2/1\",\n",
    "        trainable=True, tags={\"train\"})\n",
    "    bert_inputs = dict(\n",
    "        input_ids=input_ids,\n",
    "        input_mask=input_mask,\n",
    "        segment_ids=segment_ids)\n",
    "    bert_outputs = bert_module(bert_inputs, signature=\"tokens\", as_dict=True)\n",
    "    #pooled_output = bert_outputs[\"pooled_output\"]\n",
    "    sequence_output = tf.stop_gradient(bert_outputs[\"sequence_output\"])\n",
    "\n",
    "    feature_extracting_projection = tf.get_variable(\n",
    "        \"feature_extracting_projection\",\n",
    "        [BERT_EMBEDDING_DIM, BERT_EMBEDDING_DIM],\n",
    "        initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    logit_layer = tf.get_variable(\n",
    "        \"logit_layer\",\n",
    "        [BERT_EMBEDDING_DIM, NUM_LABELS],\n",
    "        initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "\n",
    "    with tf.variable_scope('loss'):\n",
    "        def _extract_single_embedding_vector(embedding_vector):\n",
    "            embedding_vector = tf.expand_dims(embedding_vector, axis=0)\n",
    "            res = tf.matmul(embedding_vector, feature_extracting_projection)\n",
    "            res = tf.matmul(res, logit_layer)\n",
    "            return tf.squeeze(res)\n",
    "\n",
    "        def _extract_sequence_of_embeddings(embedding_seq):\n",
    "            return tf.map_fn(_extract_single_embedding_vector, embedding_seq, infer_shape=False)\n",
    "\n",
    "        logits = tf.map_fn(_extract_sequence_of_embeddings, sequence_output, infer_shape=False)\n",
    "        logits = tf.ensure_shape(logits, [batch_size, MAX_SEQ_LENGTH, NUM_LABELS])\n",
    "        softmax = tf.nn.softmax(logits, axis=2)\n",
    "        per_timestep_loss = -tf.reduce_sum(softmax * labels_one_hot, axis=2)\n",
    "        batch_loss = tf.reduce_mean(per_timestep_loss)\n",
    "\n",
    "        predicted_labels = tf.argmax(softmax, axis=-1)\n",
    "\n",
    "    def _metric_fn(ground_truth_labels, preds):\n",
    "        accuracy = tf.metrics.accuracy(ground_truth_labels, preds)\n",
    "\n",
    "        is_ing_mask = tf.equal(ground_truth_labels, 1)\n",
    "        is_ing_preds = tf.boolean_mask(preds, is_ing_mask)\n",
    "        is_ing_labels = tf.boolean_mask(ground_truth_labels, is_ing_mask)\n",
    "        is_ing_accuracy = tf.metrics.accuracy(is_ing_labels, is_ing_preds)\n",
    "\n",
    "        is_not_ing_mask = tf.equal(ground_truth_labels, 0)\n",
    "        is_not_ing_preds = tf.boolean_mask(preds, is_not_ing_mask)\n",
    "        is_not_ing_labels = tf.boolean_mask(ground_truth_labels, is_not_ing_mask)\n",
    "        is_not_ing_accuracy = tf.metrics.accuracy(is_not_ing_labels, is_not_ing_preds)\n",
    "\n",
    "        return {\n",
    "            'accuracy': accuracy,\n",
    "            'is_ing_accuracy': is_ing_accuracy,\n",
    "            'is_not_ing_accuracy': is_not_ing_accuracy,\n",
    "        }\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        opt = tf.train.AdamOptimizer(learning_rate=0.0001, beta1=0.9, beta2=0.999, epsilon=1e-08)\n",
    "        train_op = opt.minimize(batch_loss, global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode, loss=batch_loss, train_op=train_op)\n",
    "    elif mode == tf.estimator.ModeKeys.EVAL:\n",
    "        return tf.estimator.EstimatorSpec(mode, loss=batch_loss, eval_metric_ops=_metric_fn(labels, predicted_labels))\n",
    "    elif mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=predicted_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def vocab_file():\n",
    "    vocab_file = os.path.join(os.path.abspath(''), 'small_bert_bert_uncased_L-2_H-128_A-2_1/assets/vocab.txt')\n",
    "    return vocab_file\n",
    "\n",
    "def read_vocab():\n",
    "    f = open(vocab_file(), 'rb')\n",
    "    words = f.readlines()\n",
    "    words = [word.rstrip() for word in words]\n",
    "    return words\n",
    "\n",
    "def has_ing():\n",
    "    vocab = read_vocab()\n",
    "    return [s.endswith('ing') for s in vocab]\n",
    "\n",
    "class IngLabelFunction(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(IngLabelFunction, self).__init__()\n",
    "        self.lookup = tf.constant(has_ing())\n",
    "\n",
    "    def label(self, ids):\n",
    "        res = tf.gather(self.lookup, ids)\n",
    "        res = tf.cast(res, dtype=tf.int32)\n",
    "        return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Input\n",
    "def make_input_fn(examples):\n",
    "\n",
    "    def input_fn():\n",
    "        tokenizer = create_tokenizer_from_hub_module()\n",
    "        feats = bert.run_classifier.convert_examples_to_features(examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "        vanilla_fn = bert.run_classifier.input_fn_builder(\n",
    "            features=feats,\n",
    "            seq_length=MAX_SEQ_LENGTH,\n",
    "            is_training=True,\n",
    "            drop_remainder=False\n",
    "        )\n",
    "        params = {\n",
    "            \"batch_size\": 5\n",
    "        }        \n",
    "        ds = vanilla_fn(params)\n",
    "    \n",
    "        labeler = IngLabelFunction()\n",
    "        def _add_labels(record):\n",
    "            ids = record['input_ids']\n",
    "            labels = labeler.label(ids)\n",
    "            return record, labels\n",
    "\n",
    "        ds = ds.map(_add_labels)\n",
    "        return ds\n",
    "\n",
    "    return input_fn\n",
    "\n",
    "# tf.reset_default_graph()\n",
    "# tf.disable_v2_behavior()\n",
    "\n",
    "# features = train_InputExamples[:5]\n",
    "# ds = make_input_fn(features)()._dataset\n",
    "# it = tf.data.make_one_shot_iterator(ds)\n",
    "# with tf.Session() as sess:\n",
    "#     ds_value = it.get_next()\n",
    "#     model_output = bert_model(ds_value[0], ds_value[1], tf.estimator.ModeKeys.EVAL, {'batch_size': 5})\n",
    "#     print(model_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "212, step = 201 (8.353 sec)\nINFO:tensorflow:loss = -0.9081212, step = 201 (8.353 sec)\nINFO:tensorflow:global_step/sec: 11.6001\nINFO:tensorflow:global_step/sec: 11.6001\nINFO:tensorflow:loss = -0.9371659, step = 301 (8.620 sec)\nINFO:tensorflow:loss = -0.9371659, step = 301 (8.620 sec)\nINFO:tensorflow:global_step/sec: 11.5264\nINFO:tensorflow:global_step/sec: 11.5264\nINFO:tensorflow:loss = -0.9370707, step = 401 (8.676 sec)\nINFO:tensorflow:loss = -0.9370707, step = 401 (8.676 sec)\nINFO:tensorflow:global_step/sec: 11.8141\nINFO:tensorflow:global_step/sec: 11.8141\nINFO:tensorflow:loss = -0.96170646, step = 501 (8.464 sec)\nINFO:tensorflow:loss = -0.96170646, step = 501 (8.464 sec)\nINFO:tensorflow:global_step/sec: 11.3092\nINFO:tensorflow:global_step/sec: 11.3092\nINFO:tensorflow:loss = -0.96058834, step = 601 (8.843 sec)\nINFO:tensorflow:loss = -0.96058834, step = 601 (8.843 sec)\nINFO:tensorflow:global_step/sec: 12.3816\nINFO:tensorflow:global_step/sec: 12.3816\nINFO:tensorflow:loss = -0.9644394, step = 701 (8.076 sec)\nINFO:tensorflow:loss = -0.9644394, step = 701 (8.076 sec)\nINFO:tensorflow:global_step/sec: 13.1682\nINFO:tensorflow:global_step/sec: 13.1682\nINFO:tensorflow:loss = -0.95774555, step = 801 (7.594 sec)\nINFO:tensorflow:loss = -0.95774555, step = 801 (7.594 sec)\nINFO:tensorflow:global_step/sec: 12.6519\nINFO:tensorflow:global_step/sec: 12.6519\nINFO:tensorflow:loss = -0.9662048, step = 901 (7.904 sec)\nINFO:tensorflow:loss = -0.9662048, step = 901 (7.904 sec)\nINFO:tensorflow:global_step/sec: 11.9498\nINFO:tensorflow:global_step/sec: 11.9498\nINFO:tensorflow:loss = -0.9692478, step = 1001 (8.368 sec)\nINFO:tensorflow:loss = -0.9692478, step = 1001 (8.368 sec)\nINFO:tensorflow:global_step/sec: 12.662\nINFO:tensorflow:global_step/sec: 12.662\nINFO:tensorflow:loss = -0.97924745, step = 1101 (7.898 sec)\nINFO:tensorflow:loss = -0.97924745, step = 1101 (7.898 sec)\nINFO:tensorflow:global_step/sec: 13.5981\nINFO:tensorflow:global_step/sec: 13.5981\nINFO:tensorflow:loss = -0.97525084, step = 1201 (7.354 sec)\nINFO:tensorflow:loss = -0.97525084, step = 1201 (7.354 sec)\nINFO:tensorflow:global_step/sec: 13.4206\nINFO:tensorflow:global_step/sec: 13.4206\nINFO:tensorflow:loss = -0.97632706, step = 1301 (7.452 sec)\nINFO:tensorflow:loss = -0.97632706, step = 1301 (7.452 sec)\nINFO:tensorflow:global_step/sec: 13.9769\nINFO:tensorflow:global_step/sec: 13.9769\nINFO:tensorflow:loss = -0.98462296, step = 1401 (7.154 sec)\nINFO:tensorflow:loss = -0.98462296, step = 1401 (7.154 sec)\nINFO:tensorflow:global_step/sec: 12.4471\nINFO:tensorflow:global_step/sec: 12.4471\nINFO:tensorflow:loss = -0.959087, step = 1501 (8.035 sec)\nINFO:tensorflow:loss = -0.959087, step = 1501 (8.035 sec)\nINFO:tensorflow:global_step/sec: 13.3808\nINFO:tensorflow:global_step/sec: 13.3808\nINFO:tensorflow:loss = -0.9728155, step = 1601 (7.473 sec)\nINFO:tensorflow:loss = -0.9728155, step = 1601 (7.473 sec)\nINFO:tensorflow:global_step/sec: 13.0868\nINFO:tensorflow:global_step/sec: 13.0868\nINFO:tensorflow:loss = -0.9693181, step = 1701 (7.642 sec)\nINFO:tensorflow:loss = -0.9693181, step = 1701 (7.642 sec)\nINFO:tensorflow:global_step/sec: 13.4881\nINFO:tensorflow:global_step/sec: 13.4881\nINFO:tensorflow:loss = -0.97729015, step = 1801 (7.415 sec)\nINFO:tensorflow:loss = -0.97729015, step = 1801 (7.415 sec)\nINFO:tensorflow:global_step/sec: 12.3508\nINFO:tensorflow:global_step/sec: 12.3508\nINFO:tensorflow:loss = -0.98050183, step = 1901 (8.095 sec)\nINFO:tensorflow:loss = -0.98050183, step = 1901 (8.095 sec)\nINFO:tensorflow:global_step/sec: 13.2216\nINFO:tensorflow:global_step/sec: 13.2216\nINFO:tensorflow:loss = -0.9771984, step = 2001 (7.563 sec)\nINFO:tensorflow:loss = -0.9771984, step = 2001 (7.563 sec)\nINFO:tensorflow:global_step/sec: 13.3963\nINFO:tensorflow:global_step/sec: 13.3963\nINFO:tensorflow:loss = -0.9776632, step = 2101 (7.466 sec)\nINFO:tensorflow:loss = -0.9776632, step = 2101 (7.466 sec)\nINFO:tensorflow:global_step/sec: 13.4948\nINFO:tensorflow:global_step/sec: 13.4948\nINFO:tensorflow:loss = -0.9728397, step = 2201 (7.411 sec)\nINFO:tensorflow:loss = -0.9728397, step = 2201 (7.411 sec)\nINFO:tensorflow:global_step/sec: 11.3753\nINFO:tensorflow:global_step/sec: 11.3753\nINFO:tensorflow:loss = -0.9809004, step = 2301 (8.789 sec)\nINFO:tensorflow:loss = -0.9809004, step = 2301 (8.789 sec)\nINFO:tensorflow:global_step/sec: 11.2928\nINFO:tensorflow:global_step/sec: 11.2928\nINFO:tensorflow:loss = -0.9657726, step = 2401 (8.856 sec)\nINFO:tensorflow:loss = -0.9657726, step = 2401 (8.856 sec)\nINFO:tensorflow:global_step/sec: 11.5742\nINFO:tensorflow:global_step/sec: 11.5742\nINFO:tensorflow:loss = -0.9656876, step = 2501 (8.640 sec)\nINFO:tensorflow:loss = -0.9656876, step = 2501 (8.640 sec)\nINFO:tensorflow:global_step/sec: 14.9576\nINFO:tensorflow:global_step/sec: 14.9576\nINFO:tensorflow:loss = -0.9753397, step = 2601 (6.686 sec)\nINFO:tensorflow:loss = -0.9753397, step = 2601 (6.686 sec)\nINFO:tensorflow:global_step/sec: 14.3968\nINFO:tensorflow:global_step/sec: 14.3968\nINFO:tensorflow:loss = -0.9626528, step = 2701 (6.946 sec)\nINFO:tensorflow:loss = -0.9626528, step = 2701 (6.946 sec)\nINFO:tensorflow:global_step/sec: 16.3981\nINFO:tensorflow:global_step/sec: 16.3981\nINFO:tensorflow:loss = -0.9724351, step = 2801 (6.099 sec)\nINFO:tensorflow:loss = -0.9724351, step = 2801 (6.099 sec)\nINFO:tensorflow:global_step/sec: 17.0113\nINFO:tensorflow:global_step/sec: 17.0113\nINFO:tensorflow:loss = -0.97714823, step = 2901 (5.878 sec)\nINFO:tensorflow:loss = -0.97714823, step = 2901 (5.878 sec)\nINFO:tensorflow:global_step/sec: 17.0472\nINFO:tensorflow:global_step/sec: 17.0472\nINFO:tensorflow:loss = -0.98477554, step = 3001 (5.866 sec)\nINFO:tensorflow:loss = -0.98477554, step = 3001 (5.866 sec)\nINFO:tensorflow:global_step/sec: 16.3095\nINFO:tensorflow:global_step/sec: 16.3095\nINFO:tensorflow:loss = -0.9756819, step = 3101 (6.133 sec)\nINFO:tensorflow:loss = -0.9756819, step = 3101 (6.133 sec)\nINFO:tensorflow:global_step/sec: 15.2637\nINFO:tensorflow:global_step/sec: 15.2637\nINFO:tensorflow:loss = -0.9693472, step = 3201 (6.550 sec)\nINFO:tensorflow:loss = -0.9693472, step = 3201 (6.550 sec)\nINFO:tensorflow:global_step/sec: 16.9709\nINFO:tensorflow:global_step/sec: 16.9709\nINFO:tensorflow:loss = -0.975741, step = 3301 (5.892 sec)\nINFO:tensorflow:loss = -0.975741, step = 3301 (5.892 sec)\nINFO:tensorflow:global_step/sec: 12.8021\nINFO:tensorflow:global_step/sec: 12.8021\nINFO:tensorflow:loss = -0.9632721, step = 3401 (7.811 sec)\nINFO:tensorflow:loss = -0.9632721, step = 3401 (7.811 sec)\nINFO:tensorflow:global_step/sec: 13.2954\nINFO:tensorflow:global_step/sec: 13.2954\nINFO:tensorflow:loss = -0.96497905, step = 3501 (7.521 sec)\nINFO:tensorflow:loss = -0.96497905, step = 3501 (7.521 sec)\nINFO:tensorflow:global_step/sec: 13.2139\nINFO:tensorflow:global_step/sec: 13.2139\nINFO:tensorflow:loss = -0.97738636, step = 3601 (7.568 sec)\nINFO:tensorflow:loss = -0.97738636, step = 3601 (7.568 sec)\nINFO:tensorflow:global_step/sec: 13.8776\nINFO:tensorflow:global_step/sec: 13.8776\nINFO:tensorflow:loss = -0.9820608, step = 3701 (7.206 sec)\nINFO:tensorflow:loss = -0.9820608, step = 3701 (7.206 sec)\nINFO:tensorflow:global_step/sec: 13.8658\nINFO:tensorflow:global_step/sec: 13.8658\nINFO:tensorflow:loss = -0.97905844, step = 3801 (7.212 sec)\nINFO:tensorflow:loss = -0.97905844, step = 3801 (7.212 sec)\nINFO:tensorflow:global_step/sec: 13.9026\nINFO:tensorflow:global_step/sec: 13.9026\nINFO:tensorflow:loss = -0.988484, step = 3901 (7.193 sec)\nINFO:tensorflow:loss = -0.988484, step = 3901 (7.193 sec)\nINFO:tensorflow:global_step/sec: 13.1244\nINFO:tensorflow:global_step/sec: 13.1244\nINFO:tensorflow:loss = -0.974401, step = 4001 (7.619 sec)\nINFO:tensorflow:loss = -0.974401, step = 4001 (7.619 sec)\nINFO:tensorflow:global_step/sec: 13.2173\nINFO:tensorflow:global_step/sec: 13.2173\nINFO:tensorflow:loss = -0.9683015, step = 4101 (7.569 sec)\nINFO:tensorflow:loss = -0.9683015, step = 4101 (7.569 sec)\nINFO:tensorflow:global_step/sec: 11.0347\nINFO:tensorflow:global_step/sec: 11.0347\nINFO:tensorflow:loss = -0.98073137, step = 4201 (9.060 sec)\nINFO:tensorflow:loss = -0.98073137, step = 4201 (9.060 sec)\nINFO:tensorflow:global_step/sec: 11.3145\nINFO:tensorflow:global_step/sec: 11.3145\nINFO:tensorflow:loss = -0.98861295, step = 4301 (8.838 sec)\nINFO:tensorflow:loss = -0.98861295, step = 4301 (8.838 sec)\nINFO:tensorflow:global_step/sec: 12.1912\nINFO:tensorflow:global_step/sec: 12.1912\nINFO:tensorflow:loss = -0.97756994, step = 4401 (8.205 sec)\nINFO:tensorflow:loss = -0.97756994, step = 4401 (8.205 sec)\nINFO:tensorflow:global_step/sec: 12.8076\nINFO:tensorflow:global_step/sec: 12.8076\nINFO:tensorflow:loss = -0.9729997, step = 4501 (7.805 sec)\nINFO:tensorflow:loss = -0.9729997, step = 4501 (7.805 sec)\nINFO:tensorflow:global_step/sec: 12.343\nINFO:tensorflow:global_step/sec: 12.343\nINFO:tensorflow:loss = -0.98398477, step = 4601 (8.102 sec)\nINFO:tensorflow:loss = -0.98398477, step = 4601 (8.102 sec)\nINFO:tensorflow:global_step/sec: 11.892\nINFO:tensorflow:global_step/sec: 11.892\nINFO:tensorflow:loss = -0.9667345, step = 4701 (8.410 sec)\nINFO:tensorflow:loss = -0.9667345, step = 4701 (8.410 sec)\nINFO:tensorflow:global_step/sec: 10.4141\nINFO:tensorflow:global_step/sec: 10.4141\nINFO:tensorflow:loss = -0.9730967, step = 4801 (9.604 sec)\nINFO:tensorflow:loss = -0.9730967, step = 4801 (9.604 sec)\nINFO:tensorflow:global_step/sec: 15.0436\nINFO:tensorflow:global_step/sec: 15.0436\nINFO:tensorflow:loss = -0.97628796, step = 4901 (6.645 sec)\nINFO:tensorflow:loss = -0.97628796, step = 4901 (6.645 sec)\nINFO:tensorflow:global_step/sec: 12.3274\nINFO:tensorflow:global_step/sec: 12.3274\nINFO:tensorflow:loss = -0.9778598, step = 5001 (8.113 sec)\nINFO:tensorflow:loss = -0.9778598, step = 5001 (8.113 sec)\nINFO:tensorflow:global_step/sec: 12.7428\nINFO:tensorflow:global_step/sec: 12.7428\nINFO:tensorflow:loss = -0.98243505, step = 5101 (7.846 sec)\nINFO:tensorflow:loss = -0.98243505, step = 5101 (7.846 sec)\nINFO:tensorflow:global_step/sec: 16.8772\nINFO:tensorflow:global_step/sec: 16.8772\nINFO:tensorflow:loss = -0.97627103, step = 5201 (5.925 sec)\nINFO:tensorflow:loss = -0.97627103, step = 5201 (5.925 sec)\nINFO:tensorflow:global_step/sec: 15.8246\nINFO:tensorflow:global_step/sec: 15.8246\nINFO:tensorflow:loss = -0.9716239, step = 5301 (6.320 sec)\nINFO:tensorflow:loss = -0.9716239, step = 5301 (6.320 sec)\nINFO:tensorflow:global_step/sec: 17.034\nINFO:tensorflow:global_step/sec: 17.034\nINFO:tensorflow:loss = -0.9700368, step = 5401 (5.870 sec)\nINFO:tensorflow:loss = -0.9700368, step = 5401 (5.870 sec)\nINFO:tensorflow:global_step/sec: 15.1148\nINFO:tensorflow:global_step/sec: 15.1148\nINFO:tensorflow:loss = -0.97326624, step = 5501 (6.616 sec)\nINFO:tensorflow:loss = -0.97326624, step = 5501 (6.616 sec)\nINFO:tensorflow:global_step/sec: 14.8036\nINFO:tensorflow:global_step/sec: 14.8036\nINFO:tensorflow:loss = -0.982618, step = 5601 (6.755 sec)\nINFO:tensorflow:loss = -0.982618, step = 5601 (6.755 sec)\nINFO:tensorflow:global_step/sec: 14.1632\nINFO:tensorflow:global_step/sec: 14.1632\nINFO:tensorflow:loss = -0.97476786, step = 5701 (7.061 sec)\nINFO:tensorflow:loss = -0.97476786, step = 5701 (7.061 sec)\nINFO:tensorflow:global_step/sec: 13.6169\nINFO:tensorflow:global_step/sec: 13.6169\nINFO:tensorflow:loss = -0.970121, step = 5801 (7.343 sec)\nINFO:tensorflow:loss = -0.970121, step = 5801 (7.343 sec)\nINFO:tensorflow:global_step/sec: 13.2755\nINFO:tensorflow:global_step/sec: 13.2755\nINFO:tensorflow:loss = -0.98103553, step = 5901 (7.533 sec)\nINFO:tensorflow:loss = -0.98103553, step = 5901 (7.533 sec)\nINFO:tensorflow:global_step/sec: 12.089\nINFO:tensorflow:global_step/sec: 12.089\nINFO:tensorflow:loss = -0.97169226, step = 6001 (8.271 sec)\nINFO:tensorflow:loss = -0.97169226, step = 6001 (8.271 sec)\nINFO:tensorflow:global_step/sec: 14.8997\nINFO:tensorflow:global_step/sec: 14.8997\nINFO:tensorflow:loss = -0.9701416, step = 6101 (6.712 sec)\nINFO:tensorflow:loss = -0.9701416, step = 6101 (6.712 sec)\nINFO:tensorflow:global_step/sec: 15.3133\nINFO:tensorflow:global_step/sec: 15.3133\nINFO:tensorflow:loss = -0.97328407, step = 6201 (6.530 sec)\nINFO:tensorflow:loss = -0.97328407, step = 6201 (6.530 sec)\nINFO:tensorflow:global_step/sec: 14.7759\nINFO:tensorflow:global_step/sec: 14.7759\nINFO:tensorflow:loss = -0.9701711, step = 6301 (6.768 sec)\nINFO:tensorflow:loss = -0.9701711, step = 6301 (6.768 sec)\nINFO:tensorflow:global_step/sec: 10.7629\nINFO:tensorflow:global_step/sec: 10.7629\nINFO:tensorflow:loss = -0.9795558, step = 6401 (9.291 sec)\nINFO:tensorflow:loss = -0.9795558, step = 6401 (9.291 sec)\nINFO:tensorflow:global_step/sec: 13.6755\nINFO:tensorflow:global_step/sec: 13.6755\nINFO:tensorflow:loss = -0.9780297, step = 6501 (7.313 sec)\nINFO:tensorflow:loss = -0.9780297, step = 6501 (7.313 sec)\nINFO:tensorflow:global_step/sec: 14.7734\nINFO:tensorflow:global_step/sec: 14.7734\nINFO:tensorflow:loss = -0.9794995, step = 6601 (6.772 sec)\nINFO:tensorflow:loss = -0.9794995, step = 6601 (6.772 sec)\nINFO:tensorflow:global_step/sec: 16.0666\nINFO:tensorflow:global_step/sec: 16.0666\nINFO:tensorflow:loss = -0.96706676, step = 6701 (6.220 sec)\nINFO:tensorflow:loss = -0.96706676, step = 6701 (6.220 sec)\nINFO:tensorflow:global_step/sec: 14.8528\nINFO:tensorflow:global_step/sec: 14.8528\nINFO:tensorflow:loss = -0.9764692, step = 6801 (6.733 sec)\nINFO:tensorflow:loss = -0.9764692, step = 6801 (6.733 sec)\nINFO:tensorflow:global_step/sec: 17.3226\nINFO:tensorflow:global_step/sec: 17.3226\nINFO:tensorflow:loss = -0.97334737, step = 6901 (5.772 sec)\nINFO:tensorflow:loss = -0.97334737, step = 6901 (5.772 sec)\nINFO:tensorflow:global_step/sec: 16.6698\nINFO:tensorflow:global_step/sec: 16.6698\nINFO:tensorflow:loss = -0.9842766, step = 7001 (5.999 sec)\nINFO:tensorflow:loss = -0.9842766, step = 7001 (5.999 sec)\nINFO:tensorflow:global_step/sec: 14.5304\nINFO:tensorflow:global_step/sec: 14.5304\nINFO:tensorflow:loss = -0.9733518, step = 7101 (6.882 sec)\nINFO:tensorflow:loss = -0.9733518, step = 7101 (6.882 sec)\nINFO:tensorflow:global_step/sec: 17.0077\nINFO:tensorflow:global_step/sec: 17.0077\nINFO:tensorflow:loss = -0.9749079, step = 7201 (5.880 sec)\nINFO:tensorflow:loss = -0.9749079, step = 7201 (5.880 sec)\nINFO:tensorflow:global_step/sec: 15.543\nINFO:tensorflow:global_step/sec: 15.543\nINFO:tensorflow:loss = -0.9717674, step = 7301 (6.433 sec)\nINFO:tensorflow:loss = -0.9717674, step = 7301 (6.433 sec)\nINFO:tensorflow:global_step/sec: 17.2975\nINFO:tensorflow:global_step/sec: 17.2975\nINFO:tensorflow:loss = -0.9796101, step = 7401 (5.781 sec)\nINFO:tensorflow:loss = -0.9796101, step = 7401 (5.781 sec)\nINFO:tensorflow:global_step/sec: 17.1979\nINFO:tensorflow:global_step/sec: 17.1979\nINFO:tensorflow:loss = -0.9780486, step = 7501 (5.815 sec)\nINFO:tensorflow:loss = -0.9780486, step = 7501 (5.815 sec)\nINFO:tensorflow:global_step/sec: 15.5289\nINFO:tensorflow:global_step/sec: 15.5289\nINFO:tensorflow:loss = -0.9780499, step = 7601 (6.439 sec)\nINFO:tensorflow:loss = -0.9780499, step = 7601 (6.439 sec)\nINFO:tensorflow:global_step/sec: 13.4513\nINFO:tensorflow:global_step/sec: 13.4513\nINFO:tensorflow:loss = -0.9827406, step = 7701 (7.437 sec)\nINFO:tensorflow:loss = -0.9827406, step = 7701 (7.437 sec)\nINFO:tensorflow:global_step/sec: 14.7404\nINFO:tensorflow:global_step/sec: 14.7404\nINFO:tensorflow:loss = -0.974934, step = 7801 (6.781 sec)\nINFO:tensorflow:loss = -0.974934, step = 7801 (6.781 sec)\nINFO:tensorflow:global_step/sec: 17.1887\nINFO:tensorflow:global_step/sec: 17.1887\nINFO:tensorflow:loss = -0.98118573, step = 7901 (5.817 sec)\nINFO:tensorflow:loss = -0.98118573, step = 7901 (5.817 sec)\nINFO:tensorflow:global_step/sec: 17.4429\nINFO:tensorflow:global_step/sec: 17.4429\nINFO:tensorflow:loss = -0.98589057, step = 8001 (5.733 sec)\nINFO:tensorflow:loss = -0.98589057, step = 8001 (5.733 sec)\nINFO:tensorflow:global_step/sec: 17.4702\nINFO:tensorflow:global_step/sec: 17.4702\nINFO:tensorflow:loss = -0.9686961, step = 8101 (5.725 sec)\nINFO:tensorflow:loss = -0.9686961, step = 8101 (5.725 sec)\nINFO:tensorflow:global_step/sec: 17.0515\nINFO:tensorflow:global_step/sec: 17.0515\nINFO:tensorflow:loss = -0.96557826, step = 8201 (5.864 sec)\nINFO:tensorflow:loss = -0.96557826, step = 8201 (5.864 sec)\nINFO:tensorflow:Saving checkpoints for 8238 into /Users/cpeyser/Desktop/bert/ckpts/1/model.ckpt.\nINFO:tensorflow:Saving checkpoints for 8238 into /Users/cpeyser/Desktop/bert/ckpts/1/model.ckpt.\nINFO:tensorflow:global_step/sec: 15.4433\nINFO:tensorflow:global_step/sec: 15.4433\nINFO:tensorflow:loss = -0.9733906, step = 8301 (6.475 sec)\nINFO:tensorflow:loss = -0.9733906, step = 8301 (6.475 sec)\nINFO:tensorflow:global_step/sec: 17.4217\nINFO:tensorflow:global_step/sec: 17.4217\nINFO:tensorflow:loss = -0.9671358, step = 8401 (5.740 sec)\nINFO:tensorflow:loss = -0.9671358, step = 8401 (5.740 sec)\nINFO:tensorflow:global_step/sec: 16.5688\nINFO:tensorflow:global_step/sec: 16.5688\nINFO:tensorflow:loss = -0.9765196, step = 8501 (6.036 sec)\nINFO:tensorflow:loss = -0.9765196, step = 8501 (6.036 sec)\nINFO:tensorflow:global_step/sec: 16.8837\nINFO:tensorflow:global_step/sec: 16.8837\nINFO:tensorflow:loss = -0.9796481, step = 8601 (5.923 sec)\nINFO:tensorflow:loss = -0.9796481, step = 8601 (5.923 sec)\nINFO:tensorflow:global_step/sec: 16.6356\nINFO:tensorflow:global_step/sec: 16.6356\nINFO:tensorflow:loss = -0.97808266, step = 8701 (6.019 sec)\nINFO:tensorflow:loss = -0.97808266, step = 8701 (6.019 sec)\nINFO:tensorflow:global_step/sec: 14.2208\nINFO:tensorflow:global_step/sec: 14.2208\nINFO:tensorflow:loss = -0.9796373, step = 8801 (7.024 sec)\nINFO:tensorflow:loss = -0.9796373, step = 8801 (7.024 sec)\nINFO:tensorflow:global_step/sec: 17.1486\nINFO:tensorflow:global_step/sec: 17.1486\nINFO:tensorflow:loss = -0.9827665, step = 8901 (5.831 sec)\nINFO:tensorflow:loss = -0.9827665, step = 8901 (5.831 sec)\nINFO:tensorflow:global_step/sec: 17.5353\nINFO:tensorflow:global_step/sec: 17.5353\nINFO:tensorflow:loss = -0.9859045, step = 9001 (5.704 sec)\nINFO:tensorflow:loss = -0.9859045, step = 9001 (5.704 sec)\nINFO:tensorflow:global_step/sec: 16.9942\nINFO:tensorflow:global_step/sec: 16.9942\nINFO:tensorflow:loss = -0.9905922, step = 9101 (5.884 sec)\nINFO:tensorflow:loss = -0.9905922, step = 9101 (5.884 sec)\nINFO:tensorflow:global_step/sec: 16.6053\nINFO:tensorflow:global_step/sec: 16.6053\nINFO:tensorflow:loss = -0.9749578, step = 9201 (6.023 sec)\nINFO:tensorflow:loss = -0.9749578, step = 9201 (6.023 sec)\nINFO:tensorflow:global_step/sec: 12.9848\nINFO:tensorflow:global_step/sec: 12.9848\nINFO:tensorflow:loss = -0.97652847, step = 9301 (7.701 sec)\nINFO:tensorflow:loss = -0.97652847, step = 9301 (7.701 sec)\nINFO:tensorflow:global_step/sec: 16.0279\nINFO:tensorflow:global_step/sec: 16.0279\nINFO:tensorflow:loss = -0.9702798, step = 9401 (6.239 sec)\nINFO:tensorflow:loss = -0.9702798, step = 9401 (6.239 sec)\nINFO:tensorflow:global_step/sec: 16.9303\nINFO:tensorflow:global_step/sec: 16.9303\nINFO:tensorflow:loss = -0.97810423, step = 9501 (5.906 sec)\nINFO:tensorflow:loss = -0.97810423, step = 9501 (5.906 sec)\nINFO:tensorflow:global_step/sec: 17.335\nINFO:tensorflow:global_step/sec: 17.335\nINFO:tensorflow:loss = -0.97810304, step = 9601 (5.769 sec)\nINFO:tensorflow:loss = -0.97810304, step = 9601 (5.769 sec)\nINFO:tensorflow:global_step/sec: 16.4634\nINFO:tensorflow:global_step/sec: 16.4634\nINFO:tensorflow:loss = -0.97183764, step = 9701 (6.074 sec)\nINFO:tensorflow:loss = -0.97183764, step = 9701 (6.074 sec)\nINFO:tensorflow:global_step/sec: 16.9399\nINFO:tensorflow:global_step/sec: 16.9399\nINFO:tensorflow:loss = -0.9718496, step = 9801 (5.903 sec)\nINFO:tensorflow:loss = -0.9718496, step = 9801 (5.903 sec)\nINFO:tensorflow:global_step/sec: 16.249\nINFO:tensorflow:global_step/sec: 16.249\nINFO:tensorflow:loss = -0.971842, step = 9901 (6.154 sec)\nINFO:tensorflow:loss = -0.971842, step = 9901 (6.154 sec)\nINFO:tensorflow:Saving checkpoints for 10000 into /Users/cpeyser/Desktop/bert/ckpts/1/model.ckpt.\nINFO:tensorflow:Saving checkpoints for 10000 into /Users/cpeyser/Desktop/bert/ckpts/1/model.ckpt.\nINFO:tensorflow:Loss for final step: -0.9859055.\nINFO:tensorflow:Loss for final step: -0.9859055.\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow_estimator.python.estimator.estimator.Estimator at 0x147e42550>"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "# Train\n",
    "BATCH_SIZE=5\n",
    "\n",
    "run_config = tf.estimator.RunConfig(\n",
    "    model_dir=os.path.join(os.path.abspath(''), 'ckpts/classification_128/')\n",
    ")\n",
    "\n",
    "estimator = tf.estimator.Estimator(\n",
    "    model_fn=bert_model,\n",
    "    config=run_config,\n",
    "    params= {\n",
    "        'batch_size': BATCH_SIZE\n",
    "    }\n",
    ")\n",
    "estimator.train(input_fn=make_input_fn(train_InputExamples), max_steps=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "2008 2081 1996 2034 3185 1037 4569 2307 4536 2003 2999 2007 1037 2062 6517 1998 2061 19908 2143 1012 1999 2023 3185 1010 1047 4948 2243 10229 1037 2307 3066 1997 8220 2012 2116 2500 1005 11727 1012 2009 3138 2185 2172 2051 2008 2071 2022 2985 2012 4526 1037 2062 22249 2143 1012 1026 7987 1013 1028 1026 7987 1013 1028 1047 4948 2243 1005 1055 2047 14100 9144 2007 2048 3441 1024 1061 2480 2863 5651 2005 3477 5963 1998 2028 5796 1012 4743 4381 8069 2000 4154 1047 4948 2243 1005 102\nINFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\nINFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\nINFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\nINFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\nINFO:tensorflow:label: 0 (id = 0)\nINFO:tensorflow:label: 0 (id = 0)\nINFO:tensorflow:*** Example ***\nINFO:tensorflow:*** Example ***\nINFO:tensorflow:guid: None\nINFO:tensorflow:guid: None\nINFO:tensorflow:tokens: [CLS] i saw this very emotionally painful portrayal and it was fascinating . the conflict between the public and private faces of williams and the pressure he was under is illuminated in a way that even those who knew something about him would be surprised . the cast acted superb ##ly , but michael sheen was outstanding . i only realised it was him when i saw the earlier comment . he looks completely physically different in this role , from any other role i have seen him in or as himself . williams autobiography differs markedly from his diaries , as represented in this film . the film is at times distress ##ing to watch , because of the emotional anguish displayed . however , it [SEP]\nINFO:tensorflow:tokens: [CLS] i saw this very emotionally painful portrayal and it was fascinating . the conflict between the public and private faces of williams and the pressure he was under is illuminated in a way that even those who knew something about him would be surprised . the cast acted superb ##ly , but michael sheen was outstanding . i only realised it was him when i saw the earlier comment . he looks completely physically different in this role , from any other role i have seen him in or as himself . williams autobiography differs markedly from his diaries , as represented in this film . the film is at times distress ##ing to watch , because of the emotional anguish displayed . however , it [SEP]\nINFO:tensorflow:input_ids: 101 1045 2387 2023 2200 14868 9145 13954 1998 2009 2001 17160 1012 1996 4736 2090 1996 2270 1998 2797 5344 1997 3766 1998 1996 3778 2002 2001 2104 2003 14640 1999 1037 2126 2008 2130 2216 2040 2354 2242 2055 2032 2052 2022 4527 1012 1996 3459 6051 21688 2135 1010 2021 2745 20682 2001 5151 1012 1045 2069 11323 2009 2001 2032 2043 1045 2387 1996 3041 7615 1012 2002 3504 3294 8186 2367 1999 2023 2535 1010 2013 2151 2060 2535 1045 2031 2464 2032 1999 2030 2004 2370 1012 3766 10828 12980 29295 2013 2010 18707 1010 2004 3421 1999 2023 2143 1012 1996 2143 2003 2012 2335 12893 2075 2000 3422 1010 2138 1997 1996 6832 21782 6913 1012 2174 1010 2009 102\nINFO:tensorflow:input_ids: 101 1045 2387 2023 2200 14868 9145 13954 1998 2009 2001 17160 1012 1996 4736 2090 1996 2270 1998 2797 5344 1997 3766 1998 1996 3778 2002 2001 2104 2003 14640 1999 1037 2126 2008 2130 2216 2040 2354 2242 2055 2032 2052 2022 4527 1012 1996 3459 6051 21688 2135 1010 2021 2745 20682 2001 5151 1012 1045 2069 11323 2009 2001 2032 2043 1045 2387 1996 3041 7615 1012 2002 3504 3294 8186 2367 1999 2023 2535 1010 2013 2151 2060 2535 1045 2031 2464 2032 1999 2030 2004 2370 1012 3766 10828 12980 29295 2013 2010 18707 1010 2004 3421 1999 2023 2143 1012 1996 2143 2003 2012 2335 12893 2075 2000 3422 1010 2138 1997 1996 6832 21782 6913 1012 2174 1010 2009 102\nINFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\nINFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\nINFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\nINFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\nINFO:tensorflow:label: 1 (id = 1)\nINFO:tensorflow:label: 1 (id = 1)\nINFO:tensorflow:*** Example ***\nINFO:tensorflow:*** Example ***\nINFO:tensorflow:guid: None\nINFO:tensorflow:guid: None\nINFO:tensorflow:tokens: [CLS] i made a promise that if ever i posted a comment that was less than compliment ##ary , then later felt different about it , i would return and make known my change of heart . so far , this is the first time it ' s happened . < br / > < br / > i ' m really starting to enjoy hack . something has clearly changed . the storylines seem to be much stronger . the plot may still be a tad surreal , but the characters have developed so much more depth that a surreal plot can be forgiven . i attribute this to fine acting . < br / > < br / > not every show can come charging [SEP]\nINFO:tensorflow:tokens: [CLS] i made a promise that if ever i posted a comment that was less than compliment ##ary , then later felt different about it , i would return and make known my change of heart . so far , this is the first time it ' s happened . < br / > < br / > i ' m really starting to enjoy hack . something has clearly changed . the storylines seem to be much stronger . the plot may still be a tad surreal , but the characters have developed so much more depth that a surreal plot can be forgiven . i attribute this to fine acting . < br / > < br / > not every show can come charging [SEP]\nINFO:tensorflow:input_ids: 101 1045 2081 1037 4872 2008 2065 2412 1045 6866 1037 7615 2008 2001 2625 2084 19394 5649 1010 2059 2101 2371 2367 2055 2009 1010 1045 2052 2709 1998 2191 2124 2026 2689 1997 2540 1012 2061 2521 1010 2023 2003 1996 2034 2051 2009 1005 1055 3047 1012 1026 7987 1013 1028 1026 7987 1013 1028 1045 1005 1049 2428 3225 2000 5959 20578 1012 2242 2038 4415 2904 1012 1996 22628 4025 2000 2022 2172 6428 1012 1996 5436 2089 2145 2022 1037 18819 16524 1010 2021 1996 3494 2031 2764 2061 2172 2062 5995 2008 1037 16524 5436 2064 2022 24280 1012 1045 17961 2023 2000 2986 3772 1012 1026 7987 1013 1028 1026 7987 1013 1028 2025 2296 2265 2064 2272 13003 102\nINFO:tensorflow:input_ids: 101 1045 2081 1037 4872 2008 2065 2412 1045 6866 1037 7615 2008 2001 2625 2084 19394 5649 1010 2059 2101 2371 2367 2055 2009 1010 1045 2052 2709 1998 2191 2124 2026 2689 1997 2540 1012 2061 2521 1010 2023 2003 1996 2034 2051 2009 1005 1055 3047 1012 1026 7987 1013 1028 1026 7987 1013 1028 1045 1005 1049 2428 3225 2000 5959 20578 1012 2242 2038 4415 2904 1012 1996 22628 4025 2000 2022 2172 6428 1012 1996 5436 2089 2145 2022 1037 18819 16524 1010 2021 1996 3494 2031 2764 2061 2172 2062 5995 2008 1037 16524 5436 2064 2022 24280 1012 1045 17961 2023 2000 2986 3772 1012 1026 7987 1013 1028 1026 7987 1013 1028 2025 2296 2265 2064 2272 13003 102\nINFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\nINFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\nINFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\nINFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\nINFO:tensorflow:label: 1 (id = 1)\nINFO:tensorflow:label: 1 (id = 1)\nINFO:tensorflow:*** Example ***\nINFO:tensorflow:*** Example ***\nINFO:tensorflow:guid: None\nINFO:tensorflow:guid: None\nINFO:tensorflow:tokens: [CLS] just went on youtube and finally watched this oscar - nominated animated short directed by richard con ##die . i had previously watched his funny getting started there . in this one , a couple are playing sc ##ra ##bble . the wife keeps shaking her eyes while her husband has nothing but e ' s on his side . the wife leaves for a while to vacuum her bed and bath ##tub ( ! ) before catching her husband looking at her side . briefly before this , the husband catches a tv show called \" saw ##ing for teens \" with the stars saw ##ing something and the husband getting his own saw . that program gets interrupted by a special report of a [SEP]\nINFO:tensorflow:tokens: [CLS] just went on youtube and finally watched this oscar - nominated animated short directed by richard con ##die . i had previously watched his funny getting started there . in this one , a couple are playing sc ##ra ##bble . the wife keeps shaking her eyes while her husband has nothing but e ' s on his side . the wife leaves for a while to vacuum her bed and bath ##tub ( ! ) before catching her husband looking at her side . briefly before this , the husband catches a tv show called \" saw ##ing for teens \" with the stars saw ##ing something and the husband getting his own saw . that program gets interrupted by a special report of a [SEP]\nINFO:tensorflow:input_ids: 101 2074 2253 2006 7858 1998 2633 3427 2023 7436 1011 4222 6579 2460 2856 2011 2957 9530 10265 1012 1045 2018 3130 3427 2010 6057 2893 2318 2045 1012 1999 2023 2028 1010 1037 3232 2024 2652 8040 2527 11362 1012 1996 2564 7906 5513 2014 2159 2096 2014 3129 2038 2498 2021 1041 1005 1055 2006 2010 2217 1012 1996 2564 3727 2005 1037 2096 2000 11641 2014 2793 1998 7198 28251 1006 999 1007 2077 9105 2014 3129 2559 2012 2014 2217 1012 4780 2077 2023 1010 1996 3129 11269 1037 2694 2265 2170 1000 2387 2075 2005 13496 1000 2007 1996 3340 2387 2075 2242 1998 1996 3129 2893 2010 2219 2387 1012 2008 2565 4152 7153 2011 1037 2569 3189 1997 1037 102\nINFO:tensorflow:input_ids: 101 2074 2253 2006 7858 1998 2633 3427 2023 7436 1011 4222 6579 2460 2856 2011 2957 9530 10265 1012 1045 2018 3130 3427 2010 6057 2893 2318 2045 1012 1999 2023 2028 1010 1037 3232 2024 2652 8040 2527 11362 1012 1996 2564 7906 5513 2014 2159 2096 2014 3129 2038 2498 2021 1041 1005 1055 2006 2010 2217 1012 1996 2564 3727 2005 1037 2096 2000 11641 2014 2793 1998 7198 28251 1006 999 1007 2077 9105 2014 3129 2559 2012 2014 2217 1012 4780 2077 2023 1010 1996 3129 11269 1037 2694 2265 2170 1000 2387 2075 2005 13496 1000 2007 1996 3340 2387 2075 2242 1998 1996 3129 2893 2010 2219 2387 1012 2008 2565 4152 7153 2011 1037 2569 3189 1997 1037 102\nINFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\nINFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\nINFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\nINFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\nINFO:tensorflow:label: 1 (id = 1)\nINFO:tensorflow:label: 1 (id = 1)\nINFO:tensorflow:*** Example ***\nINFO:tensorflow:*** Example ***\nINFO:tensorflow:guid: None\nINFO:tensorflow:guid: None\nINFO:tensorflow:tokens: [CLS] i am from texas and my family vacation ##ed a couple of years ago to sant ##e fe with my brother . he suggested we go to see the church with the staircase . i was absolutely blown away by the miracles that took place there . the movie is great - barbara hers ##hey and william petersen were perfect for the parts they played . it is amazing , absolutely amazing . if you have not seen the staircase in person , it is worth the trip to go see it . the wood is beautiful and the architecture is as ##tou ##nding . just being in the chapel gives me goose bumps ! to read about the history of the chapel , and then [SEP]\nINFO:tensorflow:tokens: [CLS] i am from texas and my family vacation ##ed a couple of years ago to sant ##e fe with my brother . he suggested we go to see the church with the staircase . i was absolutely blown away by the miracles that took place there . the movie is great - barbara hers ##hey and william petersen were perfect for the parts they played . it is amazing , absolutely amazing . if you have not seen the staircase in person , it is worth the trip to go see it . the wood is beautiful and the architecture is as ##tou ##nding . just being in the chapel gives me goose bumps ! to read about the history of the chapel , and then [SEP]\nINFO:tensorflow:input_ids: 101 1045 2572 2013 3146 1998 2026 2155 10885 2098 1037 3232 1997 2086 3283 2000 15548 2063 10768 2007 2026 2567 1012 2002 4081 2057 2175 2000 2156 1996 2277 2007 1996 10714 1012 1045 2001 7078 10676 2185 2011 1996 17861 2008 2165 2173 2045 1012 1996 3185 2003 2307 1011 6437 5106 14844 1998 2520 22615 2020 3819 2005 1996 3033 2027 2209 1012 2009 2003 6429 1010 7078 6429 1012 2065 2017 2031 2025 2464 1996 10714 1999 2711 1010 2009 2003 4276 1996 4440 2000 2175 2156 2009 1012 1996 3536 2003 3376 1998 1996 4294 2003 2004 24826 15683 1012 2074 2108 1999 1996 4970 3957 2033 13020 18548 999 2000 3191 2055 1996 2381 1997 1996 4970 1010 1998 2059 102\nINFO:tensorflow:input_ids: 101 1045 2572 2013 3146 1998 2026 2155 10885 2098 1037 3232 1997 2086 3283 2000 15548 2063 10768 2007 2026 2567 1012 2002 4081 2057 2175 2000 2156 1996 2277 2007 1996 10714 1012 1045 2001 7078 10676 2185 2011 1996 17861 2008 2165 2173 2045 1012 1996 3185 2003 2307 1011 6437 5106 14844 1998 2520 22615 2020 3819 2005 1996 3033 2027 2209 1012 2009 2003 6429 1010 7078 6429 1012 2065 2017 2031 2025 2464 1996 10714 1999 2711 1010 2009 2003 4276 1996 4440 2000 2175 2156 2009 1012 1996 3536 2003 3376 1998 1996 4294 2003 2004 24826 15683 1012 2074 2108 1999 1996 4970 3957 2033 13020 18548 999 2000 3191 2055 1996 2381 1997 1996 4970 1010 1998 2059 102\nINFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\nINFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\nINFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\nINFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\nINFO:tensorflow:label: 1 (id = 1)\nINFO:tensorflow:label: 1 (id = 1)\nINFO:tensorflow:Calling model_fn.\nINFO:tensorflow:Calling model_fn.\nINFO:tensorflow:Saver not created because there are no variables in the graph to restore\nINFO:tensorflow:Saver not created because there are no variables in the graph to restore\nINFO:tensorflow:Done calling model_fn.\nINFO:tensorflow:Done calling model_fn.\nINFO:tensorflow:Starting evaluation at 2020-08-03T11:48:55Z\nINFO:tensorflow:Starting evaluation at 2020-08-03T11:48:55Z\nINFO:tensorflow:Graph was finalized.\nINFO:tensorflow:Graph was finalized.\nINFO:tensorflow:Restoring parameters from /Users/cpeyser/Desktop/bert/ckpts/1/model.ckpt-10000\nINFO:tensorflow:Restoring parameters from /Users/cpeyser/Desktop/bert/ckpts/1/model.ckpt-10000\nINFO:tensorflow:Running local_init_op.\nINFO:tensorflow:Running local_init_op.\nINFO:tensorflow:Done running local_init_op.\nINFO:tensorflow:Done running local_init_op.\nINFO:tensorflow:Evaluation [100/1000]\nINFO:tensorflow:Evaluation [100/1000]\nINFO:tensorflow:Evaluation [200/1000]\nINFO:tensorflow:Evaluation [200/1000]\nINFO:tensorflow:Evaluation [300/1000]\nINFO:tensorflow:Evaluation [300/1000]\nINFO:tensorflow:Evaluation [400/1000]\nINFO:tensorflow:Evaluation [400/1000]\nINFO:tensorflow:Evaluation [500/1000]\nINFO:tensorflow:Evaluation [500/1000]\nINFO:tensorflow:Evaluation [600/1000]\nINFO:tensorflow:Evaluation [600/1000]\nINFO:tensorflow:Evaluation [700/1000]\nINFO:tensorflow:Evaluation [700/1000]\nINFO:tensorflow:Evaluation [800/1000]\nINFO:tensorflow:Evaluation [800/1000]\nINFO:tensorflow:Evaluation [900/1000]\nINFO:tensorflow:Evaluation [900/1000]\nINFO:tensorflow:Evaluation [1000/1000]\nINFO:tensorflow:Evaluation [1000/1000]\nINFO:tensorflow:Finished evaluation at 2020-08-03-11:49:17\nINFO:tensorflow:Finished evaluation at 2020-08-03-11:49:17\nINFO:tensorflow:Saving dict for global step 10000: accuracy = 0.9769422, global_step = 10000, is_ing_accuracy = 0.0, is_not_ing_accuracy = 1.0, loss = -0.97691745\nINFO:tensorflow:Saving dict for global step 10000: accuracy = 0.9769422, global_step = 10000, is_ing_accuracy = 0.0, is_not_ing_accuracy = 1.0, loss = -0.97691745\nINFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: /Users/cpeyser/Desktop/bert/ckpts/1/model.ckpt-10000\nINFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: /Users/cpeyser/Desktop/bert/ckpts/1/model.ckpt-10000\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'accuracy': 0.9769422,\n 'global_step': 10000,\n 'is_ing_accuracy': 0.0,\n 'is_not_ing_accuracy': 1.0,\n 'loss': -0.97691745}"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "estimator.evaluate(input_fn=make_input_fn(test_InputExamples), steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}